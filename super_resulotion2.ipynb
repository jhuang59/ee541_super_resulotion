{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import os, shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils as utils\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "data_dir=\"/Users/huangjie/ee541_super_resulotion/data\"\n",
    "\n",
    "# Load the data using the ImageFolder dataset class\n",
    "batch_size=32\n",
    "\n",
    "train_hr = os.path.join(data_dir,'training_hr')\n",
    "train_lr = os.path.join(data_dir,'training_lr/X2')\n",
    "val_hr = os.path.join(data_dir,'validation_hr')\n",
    "val_lr = os.path.join(data_dir,'validation_lr/X2')\n",
    "test_hr = os.path.join(data_dir,'test_hr')\n",
    "test_lr = os.path.join(data_dir,'test_lr/X2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image with smallest height: /Users/huangjie/ee541_super_resulotion/data/training_lr/X2/0437x2.png Height: 324\n",
      "Image with smallest width: /Users/huangjie/ee541_super_resulotion/data/training_lr/X2/0350x2.png Width: 558\n"
     ]
    }
   ],
   "source": [
    "#SKIP\n",
    "\n",
    "#find smallest dimensions\n",
    "\n",
    "image_files1 = [os.path.join(test_lr, file) for file in os.listdir(test_lr) if file.endswith('.png')]\n",
    "image_files2 = [os.path.join(train_lr, file) for file in os.listdir(train_lr) if file.endswith('.png')]\n",
    "image_files3 = [os.path.join(val_lr, file) for file in os.listdir(val_lr) if file.endswith('.png')]\n",
    "image_files = image_files1 + image_files2 + image_files3\n",
    "\n",
    "min_height = float('inf')\n",
    "min_width = float('inf')\n",
    "min_height_image = None\n",
    "min_width_image = None\n",
    "\n",
    "for image_path in image_files:\n",
    "    image = Image.open(image_path)\n",
    "    width, height = image.size\n",
    "    if height < min_height:\n",
    "        min_height = height\n",
    "        min_height_image = image_path\n",
    "    if width < min_width:\n",
    "        min_width = width\n",
    "        min_width_image = image_path\n",
    "\n",
    "\n",
    "print(\"Image with smallest height:\", min_height_image, \"Height:\", min_height)\n",
    "print(\"Image with smallest width:\", min_width_image, \"Width:\", min_width)\n",
    "#ensuring that min height and min width will not round to be outside of range\n",
    "min_height = min_height-1\n",
    "min_width = min_width-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine patch size\n",
    "min_height = 36\n",
    "min_width = 36\n",
    "\n",
    "# Define the transformations to be applied to the images\n",
    "#seed = 123\n",
    "#generator = torch.Generator()\n",
    "#generator.manual_seed(seed)\n",
    "from torchvision.transforms.functional import rotate\n",
    "from torchvision.transforms.functional import hflip\n",
    "transform = {\n",
    "    'train_input': transforms.Compose([\n",
    "        transforms.CenterCrop([min_height,min_width]),\n",
    "        # transforms.RandomApply([\n",
    "        #   transforms.RandomHorizontalFlip(p=0.2),\n",
    "        #   transforms.RandomVerticalFlip(p=0.2),\n",
    "        #   transforms.RandomRotation(30),\n",
    "        # ], p=0.5),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'train_output': transforms.Compose([\n",
    "        transforms.CenterCrop([min_height*2,min_width*2]),\n",
    "        # transforms.RandomApply([\n",
    "        #   transforms.RandomHorizontalFlip(p=0.2),\n",
    "        #   transforms.RandomVerticalFlip(p=0.2),\n",
    "        #   transforms.RandomRotation(30),\n",
    "        # ], p=0.5),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'val_test_input': transforms.Compose([\n",
    "        transforms.CenterCrop([min_height,min_width]),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'val_test_output': transforms.Compose([\n",
    "        transforms.CenterCrop([min_height*2,min_width*2]),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'val_test_input_rotate': transforms.Compose([\n",
    "        transforms.Lambda(lambda x: rotate(x, 30)),\n",
    "        transforms.CenterCrop([min_height,min_width]),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'val_test_output_rotate': transforms.Compose([\n",
    "        transforms.Lambda(lambda x: rotate(x, 30)),\n",
    "        transforms.CenterCrop([min_height*2,min_width*2]),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'train_input_rotate': transforms.Compose([\n",
    "        transforms.Lambda(lambda x: rotate(x, 30)),\n",
    "        transforms.CenterCrop([min_height,min_width]),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'train_output_rotate': transforms.Compose([\n",
    "        transforms.Lambda(lambda x: rotate(x, 30)),\n",
    "        transforms.CenterCrop([min_height*2,min_width*2]),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'train_input_flip': transforms.Compose([\n",
    "        transforms.Lambda(lambda x: hflip(x)),\n",
    "        transforms.CenterCrop([min_height,min_width]),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'train_output_flip': transforms.Compose([\n",
    "        transforms.Lambda(lambda x: hflip(x)),\n",
    "        transforms.CenterCrop([min_height*2,min_width*2]),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Div2K(Dataset):\n",
    "  def __init__(self, input_folder, output_folder, transform_input, transform_output):\n",
    "    self.input_folder = input_folder\n",
    "    self.output_folder = output_folder\n",
    "    self.transform_input = transform_input\n",
    "    self.transform_output = transform_output\n",
    "    self.input_images = sorted([file for file in os.listdir(input_folder) if file.endswith('.png')])\n",
    "    self.output_images = sorted([file for file in os.listdir(output_folder) if file.endswith('.png')])\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.input_images)\n",
    "  def __getitem__(self,index):\n",
    "    input_image_path = os.path.join(self.input_folder, self.input_images[index])\n",
    "    output_image_path = os.path.join(self.output_folder, self.output_images[index])\n",
    "    input_image = Image.open(input_image_path).convert('RGB')\n",
    "    output_image = Image.open(output_image_path).convert('RGB')\n",
    "\n",
    "    input_image = self.transform_input(input_image)\n",
    "    output_image = self.transform_output(output_image)\n",
    "    return input_image, output_image\n",
    "\n",
    "train_dataset = Div2K(train_lr, train_hr, transform_input=transform['train_input'],transform_output=transform['train_output'])\n",
    "train_dataset_rotate = Div2K(train_lr, train_hr, transform_input=transform['train_input_rotate'],transform_output=transform['train_output_rotate'])\n",
    "train_dataset_flip = Div2K(train_lr, train_hr, transform_input=transform['train_input_flip'],transform_output=transform['train_output_flip'])\n",
    "test_dataset = Div2K(test_lr, test_hr, transform_input = transform['val_test_input'],transform_output=transform['val_test_output'])\n",
    "val_dataset = Div2K(val_lr, val_hr, transform_input = transform['val_test_input'],transform_output=transform['val_test_output'])\n",
    "\n",
    "temp = torch.utils.data.ConcatDataset([train_dataset, train_dataset_rotate])\n",
    "train_dataset_combined = torch.utils.data.ConcatDataset([temp, train_dataset_flip])\n",
    "\n",
    "batch_size = 24\n",
    "\n",
    "train_dataloader_rotate = DataLoader(train_dataset_rotate, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "train_dataloader_flip = DataLoader(train_dataset_flip, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "train_dataloader_combined = DataLoader(train_dataset_combined, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "#train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size = batch_size, shuffle=True, num_workers=2)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <function <lambda> at 0x7f77d9e8f040>: attribute lookup <lambda> on __main__ failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#Chekcihng dataloader dimensions (opt)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m data_iter \u001b[39m=\u001b[39m \u001b[39miter\u001b[39;49m(train_dataloader_combined)\n\u001b[1;32m      3\u001b[0m lr_images, hr_images \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(data_iter)\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mLow-resolution images:\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ee541_work/lib/python3.9/site-packages/torch/utils/data/dataloader.py:444\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[1;32m    443\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ee541_work/lib/python3.9/site-packages/torch/utils/data/dataloader.py:390\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    389\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 390\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ee541_work/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1077\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1070\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1071\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m   1073\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m   1074\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m   1075\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m   1076\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m-> 1077\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[1;32m   1078\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[1;32m   1079\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ee541_work/lib/python3.9/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ee541_work/lib/python3.9/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ee541_work/lib/python3.9/multiprocessing/context.py:284\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    282\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    283\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_posix\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[0;32m--> 284\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ee541_work/lib/python3.9/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fds \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(process_obj)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ee541_work/lib/python3.9/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturncode \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinalizer \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_launch(process_obj)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ee541_work/lib/python3.9/multiprocessing/popen_spawn_posix.py:47\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, fp)\n\u001b[0;32m---> 47\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, fp)\n\u001b[1;32m     48\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ee541_work/lib/python3.9/multiprocessing/reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, file, protocol)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <function <lambda> at 0x7f77d9e8f040>: attribute lookup <lambda> on __main__ failed"
     ]
    }
   ],
   "source": [
    "#Chekcihng dataloader dimensions (opt)\n",
    "data_iter = iter(train_dataloader_combined)\n",
    "lr_images, hr_images = next(data_iter)\n",
    "print(\"Low-resolution images:\")\n",
    "print(\"Shape:\", lr_images.shape)\n",
    "print(\"Data type:\", lr_images.dtype)\n",
    "\n",
    "print(\"\\nHigh-resolution images:\")\n",
    "print(\"Shape:\", hr_images.shape)\n",
    "print(\"Data type:\", hr_images.dtype)\n",
    "\n",
    "#displaying some image pairs (opt)\n",
    "i=0\n",
    "for lr_images,hr_images in train_dataloader_combined:\n",
    "    # Plot the first image in the batch\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    #expected shape (height, width, num_channels)\n",
    "    lr_image = lr_images[0].permute(1, 2, 0)\n",
    "    ax[0].imshow(lr_image)\n",
    "    ax[0].set_title('Low-resolution')\n",
    "    hr_image = hr_images[0].permute(1, 2, 0)\n",
    "    ax[1].imshow(hr_image)\n",
    "    ax[1].set_title('High-resolution')\n",
    "    plt.show()\n",
    "    i+=1\n",
    "    if(i>2):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, num_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(num_channels, num_channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(num_channels)\n",
    "        self.prelu = nn.PReLU()\n",
    "        self.conv2 = nn.Conv2d(num_channels, num_channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(num_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.prelu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += residual\n",
    "        return out\n",
    "\n",
    "class UpsampleBlock(nn.Module):\n",
    "    def __init__(self, num_channels):\n",
    "        super(UpsampleBlock, self).__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(num_channels, 4*num_channels, kernel_size=3, padding=1)\n",
    "        self.pixel_shuffle = nn.PixelShuffle(2)\n",
    "        self.prelu = nn.PReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.pixel_shuffle(out)\n",
    "        out = self.prelu(out)\n",
    "        return out\n",
    "\n",
    "class SRResNet(nn.Module):\n",
    "    def __init__(self, upscale_factor=2, num_channels=64, num_residual_blocks=16):\n",
    "        super(SRResNet, self).__init__()\n",
    "\n",
    "        # First convolutional layer\n",
    "        #nn.Conv2d(number of input channels,number of output channels,kernel size,padding)\n",
    "        #applied symmetric padding, the size of output is the same as that of input\n",
    "        self.conv1 = nn.Conv2d(3, num_channels, kernel_size=9, padding=4)\n",
    "\n",
    "        # Residual blocks\n",
    "        res_blocks = []\n",
    "        for _ in range(num_residual_blocks):\n",
    "            res_blocks.append(ResidualBlock(num_channels))\n",
    "\n",
    "        self.res_blocks = nn.Sequential(*res_blocks)\n",
    "\n",
    "        # Second convolutional layer\n",
    "        self.conv2 = nn.Conv2d(num_channels, num_channels, kernel_size=3, padding=1)\n",
    "\n",
    "        # Upscaling layers\n",
    "        upsample_blocks = []\n",
    "        for _ in range(int(upscale_factor/2)):\n",
    "            upsample_blocks.append(UpsampleBlock(num_channels))\n",
    "\n",
    "        self.upsample = nn.Sequential(*upsample_blocks)\n",
    "\n",
    "        # Third convolutional layer\n",
    "        self.conv3 = nn.Conv2d(num_channels, 3, kernel_size=9, padding=4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.res_blocks(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.upsample(out)\n",
    "        out = self.conv3(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <function <lambda> at 0x7f90636823a0>: attribute lookup <lambda> on __main__ failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m val_psnr \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m     25\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m---> 26\u001b[0m \u001b[39mfor\u001b[39;00m inputs, targets \u001b[39min\u001b[39;00m train_dataloader_combined:\n\u001b[1;32m     27\u001b[0m     inputs, targets \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(device), targets\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     28\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ee541_work/lib/python3.9/site-packages/torch/utils/data/dataloader.py:444\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[1;32m    443\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ee541_work/lib/python3.9/site-packages/torch/utils/data/dataloader.py:390\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    389\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 390\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ee541_work/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1077\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1070\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1071\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m   1073\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m   1074\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m   1075\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m   1076\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m-> 1077\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[1;32m   1078\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[1;32m   1079\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ee541_work/lib/python3.9/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ee541_work/lib/python3.9/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ee541_work/lib/python3.9/multiprocessing/context.py:284\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    282\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    283\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_posix\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[0;32m--> 284\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ee541_work/lib/python3.9/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fds \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(process_obj)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ee541_work/lib/python3.9/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturncode \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinalizer \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_launch(process_obj)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ee541_work/lib/python3.9/multiprocessing/popen_spawn_posix.py:47\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, fp)\n\u001b[0;32m---> 47\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, fp)\n\u001b[1;32m     48\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ee541_work/lib/python3.9/multiprocessing/reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, file, protocol)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <function <lambda> at 0x7f90636823a0>: attribute lookup <lambda> on __main__ failed"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import math\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SRResNet()\n",
    "model.to(device)\n",
    "\n",
    "def psnr(mse, max_val=1.0):\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    return 20 * math.log10(max_val / math.sqrt(mse))\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001,weight_decay=1e-4)\n",
    "train_losses, val_losses = [], []\n",
    "train_psnrs, val_psnrs = [], []\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    val_loss = 0.0\n",
    "    train_psnr = 0.0\n",
    "    val_psnr = 0.0\n",
    "    \n",
    "    model.train()\n",
    "    for inputs, targets in train_dataloader_combined:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        mse_loss = criterion(outputs, targets)\n",
    "        psnr_loss = psnr(mse_loss.item())\n",
    "\n",
    "        mse_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += mse_loss.item() * inputs.size(0)\n",
    "        train_psnr += psnr_loss * inputs.size(0)\n",
    "\n",
    "    train_loss /= len(train_dataloader_combined.dataset)\n",
    "    train_psnr /= len(train_dataloader_combined.dataset)\n",
    "    train_losses.append(train_loss)\n",
    "    train_psnrs.append(train_psnr)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_dataloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            mse_loss = criterion(outputs, targets)\n",
    "            psnr_loss = psnr(mse_loss.item())\n",
    "            val_loss += mse_loss.item() * inputs.size(0)\n",
    "            val_psnr += psnr_loss * inputs.size(0)\n",
    "        val_loss /= len(val_dataloader.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "        val_psnr /= len(val_dataloader.dataset)\n",
    "        val_psnrs.append(val_psnr)\n",
    "    print('Epoch [{}/{}], Train Loss: {:.4f}, Train PSNR: {:.4f}, Val Loss: {:.4f}, Val PSNR: {:.4f}'\n",
    "          .format(epoch+1, num_epochs, train_loss, train_psnr, val_loss, val_psnr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train_psnrs, label='Training PSNR')\n",
    "plt.plot(val_psnrs, label='Validation PSNR')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('PSNR')\n",
    "plt.title('Training and Validation PSNR')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test loss\n",
    "def psnr(mse, max_val=1.0):\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    return 20 * math.log10(max_val / math.sqrt(mse))\n",
    "\n",
    "num_epochs = 10\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_psnr = 0.0\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_dataloader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        mse_loss = criterion(outputs, targets)\n",
    "        psnr_loss = psnr(mse_loss.item())\n",
    "        test_loss += mse_loss.item() * inputs.size(0)\n",
    "        test_psnr += psnr_loss * inputs.size(0)\n",
    "    test_loss /= len(test_dataloader.dataset)\n",
    "    test_psnr /= len(test_dataloader.dataset)\n",
    "\n",
    "print('Test Loss: {:.4f}, Test PSNR: {:.4f}'.format(test_loss,test_psnr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a few examples of HR image, LR image, and trained \n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_dataloader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        break\n",
    "    inputs = inputs.cpu()\n",
    "    targets = targets.cpu()\n",
    "    outputs = outputs.cpu()\n",
    "    for i in range(3):\n",
    "        input_img = transforms.ToPILImage()(inputs[i])\n",
    "        target_img = transforms.ToPILImage()(targets[i])\n",
    "        output_img = transforms.ToPILImage()(outputs[i])\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(input_img)\n",
    "        plt.title('LR Image')\n",
    "        plt.axis('off')\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(output_img)\n",
    "        plt.title('Trained Output')\n",
    "        plt.axis('off')\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(target_img)\n",
    "        plt.title('HR Image')\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ee541_work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
